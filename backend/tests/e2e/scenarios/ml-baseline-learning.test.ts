/**
 * E2E Test: ML Baseline Learning After 100 Automations
 *
 * Tests the ML baseline establishment workflow:
 * 1. Process exactly 100 automations
 * 2. Record baseline metrics (precision, recall, F1)
 * 3. Detect drift when performance degrades
 * 4. Adapt baseline over time (rolling window)
 */

import { baselineManager, BaselineManagerService } from '../../../src/services/detection/baseline-manager.service';
import { detectionMetrics } from '../../../src/services/detection/detection-metrics.service';
import { DetectionResult, GroundTruthLabel } from '../../../src/services/detection/detection-metrics.service';
import { TestDatabase } from '../../helpers/test-database';
import crypto from 'crypto';
import * as path from 'path';
import * as fs from 'fs';

describe('E2E: ML Baseline Learning', () => {
  let testDb: TestDatabase;
  let testBaselineManager: BaselineManagerService;
  let baselinesDir: string;

  beforeAll(async () => {
    testDb = TestDatabase.getInstance();
    await testDb.beginTransaction();

    // Create isolated baselines directory for testing
    baselinesDir = path.join(__dirname, '../../fixtures/baselines-test', crypto.randomUUID());
    if (!fs.existsSync(baselinesDir)) {
      fs.mkdirSync(baselinesDir, { recursive: true });
    }
    testBaselineManager = new BaselineManagerService(baselinesDir);
  });

  afterAll(async () => {
    await testDb.rollbackTransaction();

    // Cleanup test baselines directory
    if (fs.existsSync(baselinesDir)) {
      fs.rmSync(baselinesDir, { recursive: true, force: true });
    }
  });

  describe('Baseline Establishment (100 Automations)', () => {
    it('should establish baseline after processing exactly 100 automations', async () => {
      const detectorName = 'ai-provider-detector';

      // Generate 100 automation detections with realistic accuracy
      const { predictions, groundTruth } = generateDetectionDataset(100, {
        precision: 0.92,
        recall: 0.95
      });

      // Calculate metrics from 100 automations
      const report = detectionMetrics.generateReport(predictions, groundTruth);

      // Record baseline
      const baselineId = testBaselineManager.recordBaseline(detectorName, {
        precision: report.precision,
        recall: report.recall,
        f1Score: report.f1Score,
        timestamp: new Date(),
        sampleSize: 100,
        detectorVersion: '1.0'
      });

      // Verify baseline recorded
      expect(baselineId).toBeDefined();
      expect(baselineId).toContain('ai-provider-detector');

      // Verify baseline can be retrieved
      const baseline = testBaselineManager.getLatestBaseline(detectorName);
      expect(baseline).toBeDefined();
      expect(baseline?.sampleSize).toBe(100);
      expect(baseline?.precision).toBeCloseTo(0.92, 1);
      expect(baseline?.recall).toBeCloseTo(0.95, 1);
      expect(baseline?.f1Score).toBeGreaterThan(0.90);

      console.log('âœ… Baseline established:', {
        precision: baseline?.precision,
        recall: baseline?.recall,
        f1Score: baseline?.f1Score,
        sampleSize: baseline?.sampleSize
      });
    });

    it('should include baseline metadata (version, timestamp, sample size)', async () => {
      const detectorName = 'velocity-detector';

      const { predictions, groundTruth } = generateDetectionDataset(100, {
        precision: 0.88,
        recall: 0.93
      });

      const report = detectionMetrics.generateReport(predictions, groundTruth);
      const timestamp = new Date();

      testBaselineManager.recordBaseline(detectorName, {
        precision: report.precision,
        recall: report.recall,
        f1Score: report.f1Score,
        timestamp,
        sampleSize: 100,
        detectorVersion: '2.1'
      });

      const baseline = testBaselineManager.getLatestBaseline(detectorName);

      expect(baseline).toBeDefined();
      expect(baseline?.detectorVersion).toBe('2.1');
      expect(baseline?.sampleSize).toBe(100);
      expect(baseline?.timestamp).toBeDefined();
      expect(new Date(baseline!.timestamp).getTime()).toBeCloseTo(timestamp.getTime(), -2);
    });

    it('should fail to establish baseline with insufficient data (< 100 automations)', async () => {
      const detectorName = 'batch-operation-detector';

      // Only 50 automations (insufficient)
      const { predictions, groundTruth } = generateDetectionDataset(50, {
        precision: 0.90,
        recall: 0.92
      });

      const report = detectionMetrics.generateReport(predictions, groundTruth);

      // This should still work but we can verify the sample size
      const baselineId = testBaselineManager.recordBaseline(detectorName, {
        precision: report.precision,
        recall: report.recall,
        f1Score: report.f1Score,
        timestamp: new Date(),
        sampleSize: 50, // Explicitly marked as insufficient
        detectorVersion: '1.0'
      });

      const baseline = testBaselineManager.getLatestBaseline(detectorName);

      // Verify it recorded but marked as small sample
      expect(baseline?.sampleSize).toBe(50);
      expect(baseline?.sampleSize).toBeLessThan(100); // Flag for insufficient data
    });
  });

  describe('Drift Detection', () => {
    it('should detect precision drift when performance drops â‰¥5%', async () => {
      const detectorName = 'precision-drift-detector';

      // Establish baseline with 92% precision
      const { predictions: baselinePreds, groundTruth: baselineGT } = generateDetectionDataset(100, {
        precision: 0.92,
        recall: 0.95
      });

      const baselineReport = detectionMetrics.generateReport(baselinePreds, baselineGT);
      testBaselineManager.recordBaseline(detectorName, {
        ...baselineReport,
        timestamp: new Date(),
        sampleSize: 100,
        detectorVersion: '1.0'
      });

      // Simulate degraded detection (86% precision = 6.5% drop)
      const { predictions: currentPreds, groundTruth: currentGT } = generateDetectionDataset(100, {
        precision: 0.86, // 6.5% drop from baseline
        recall: 0.95
      });

      const comparison = testBaselineManager.compareToBaseline(detectorName, currentPreds, currentGT);

      expect(comparison.driftDetected).toBe(true);
      expect(comparison.alerts.length).toBeGreaterThan(0);

      const precisionAlert = comparison.alerts.find(a => a.metric === 'precision');
      expect(precisionAlert).toBeDefined();
      expect(precisionAlert?.severity).toBe('warning'); // 6.5% drop = warning
      expect(precisionAlert?.percentageChange).toBeLessThan(-0.05); // More than 5% drop
      expect(precisionAlert?.message).toContain('Precision dropped');

      console.log('ðŸš¨ Drift detected:', precisionAlert?.message);
    });

    it('should detect critical drift when precision drops â‰¥7%', async () => {
      const detectorName = 'critical-drift-detector';

      // Establish baseline
      const { predictions: baselinePreds, groundTruth: baselineGT } = generateDetectionDataset(100, {
        precision: 0.92,
        recall: 0.95
      });

      const baselineReport = detectionMetrics.generateReport(baselinePreds, baselineGT);
      testBaselineManager.recordBaseline(detectorName, {
        ...baselineReport,
        timestamp: new Date(),
        sampleSize: 100,
        detectorVersion: '1.0'
      });

      // Simulate severe degradation (84% precision = 8.7% drop)
      const { predictions: currentPreds, groundTruth: currentGT } = generateDetectionDataset(100, {
        precision: 0.84, // 8.7% drop
        recall: 0.95
      });

      const comparison = testBaselineManager.compareToBaseline(detectorName, currentPreds, currentGT);

      const precisionAlert = comparison.alerts.find(a => a.metric === 'precision');
      expect(precisionAlert?.severity).toBe('critical'); // â‰¥7% drop = critical
      expect(Math.abs(precisionAlert!.percentageChange)).toBeGreaterThanOrEqual(0.07);
    });

    it('should detect recall drift when recall drops â‰¥3%', async () => {
      const detectorName = 'recall-drift-detector';

      // Establish baseline
      const { predictions: baselinePreds, groundTruth: baselineGT } = generateDetectionDataset(100, {
        precision: 0.92,
        recall: 0.95
      });

      const baselineReport = detectionMetrics.generateReport(baselinePreds, baselineGT);
      testBaselineManager.recordBaseline(detectorName, {
        ...baselineReport,
        timestamp: new Date(),
        sampleSize: 100,
        detectorVersion: '1.0'
      });

      // Recall drops to 91% (4.2% drop)
      const { predictions: currentPreds, groundTruth: currentGT } = generateDetectionDataset(100, {
        precision: 0.92,
        recall: 0.91 // 4.2% drop
      });

      const comparison = testBaselineManager.compareToBaseline(detectorName, currentPreds, currentGT);

      const recallAlert = comparison.alerts.find(a => a.metric === 'recall');
      expect(recallAlert).toBeDefined();
      expect(recallAlert?.severity).toBe('warning'); // â‰¥3% drop
      expect(Math.abs(recallAlert!.percentageChange)).toBeGreaterThanOrEqual(0.03);
    });

    it('should NOT alert when performance improves', async () => {
      const detectorName = 'improvement-detector';

      // Establish baseline
      const { predictions: baselinePreds, groundTruth: baselineGT } = generateDetectionDataset(100, {
        precision: 0.88,
        recall: 0.90
      });

      const baselineReport = detectionMetrics.generateReport(baselinePreds, baselineGT);
      testBaselineManager.recordBaseline(detectorName, {
        ...baselineReport,
        timestamp: new Date(),
        sampleSize: 100,
        detectorVersion: '1.0'
      });

      // Performance improves
      const { predictions: currentPreds, groundTruth: currentGT } = generateDetectionDataset(100, {
        precision: 0.93, // Improved from 0.88
        recall: 0.95     // Improved from 0.90
      });

      const comparison = testBaselineManager.compareToBaseline(detectorName, currentPreds, currentGT);

      expect(comparison.driftDetected).toBe(false);
      expect(comparison.alerts.length).toBe(0); // No alerts for improvements
    });
  });

  describe('Baseline Adaptation (Rolling Window)', () => {
    it('should adapt baseline over time with rolling window', async () => {
      const detectorName = 'adaptive-detector';

      // Initial baseline (t=0)
      const { predictions: batch1Preds, groundTruth: batch1GT } = generateDetectionDataset(100, {
        precision: 0.88,
        recall: 0.90
      });

      const batch1Report = detectionMetrics.generateReport(batch1Preds, batch1GT);
      testBaselineManager.recordBaseline(detectorName, {
        ...batch1Report,
        timestamp: new Date(Date.now() - 7 * 24 * 60 * 60 * 1000), // 7 days ago
        sampleSize: 100,
        detectorVersion: '1.0'
      });

      const initialBaseline = testBaselineManager.getLatestBaseline(detectorName);
      expect(initialBaseline?.precision).toBeCloseTo(0.88, 2);

      // Process 100 more automations with improved detection (t=1)
      const { predictions: batch2Preds, groundTruth: batch2GT } = generateDetectionDataset(100, {
        precision: 0.92,
        recall: 0.94
      });

      const batch2Report = detectionMetrics.generateReport(batch2Preds, batch2GT);
      testBaselineManager.recordBaseline(detectorName, {
        ...batch2Report,
        timestamp: new Date(), // Now
        sampleSize: 100,
        detectorVersion: '1.0'
      });

      // Verify baseline updated to latest metrics
      const updatedBaseline = testBaselineManager.getLatestBaseline(detectorName);
      expect(updatedBaseline?.precision).toBeCloseTo(0.92, 2);
      expect(updatedBaseline?.sampleSize).toBe(100);

      // Verify old baseline still in history
      const history = testBaselineManager.getBaselineHistory(detectorName, 10);
      expect(history.length).toBe(2);
      expect(history[0].precision).toBeCloseTo(0.92, 2); // Latest
      expect(history[1].precision).toBeCloseTo(0.88, 2); // Old
    });

    it('should maintain limited baseline history (max 10)', async () => {
      const detectorName = 'history-limit-detector';

      // Create 15 baselines
      for (let i = 0; i < 15; i++) {
        const { predictions, groundTruth } = generateDetectionDataset(100, {
          precision: 0.85 + (i * 0.01), // Gradually improving
          recall: 0.90
        });

        const report = detectionMetrics.generateReport(predictions, groundTruth);
        testBaselineManager.recordBaseline(detectorName, {
          ...report,
          timestamp: new Date(Date.now() - (15 - i) * 24 * 60 * 60 * 1000),
          sampleSize: 100,
          detectorVersion: '1.0'
        });
      }

      // Verify only 10 most recent baselines kept
      const history = testBaselineManager.getBaselineHistory(detectorName);
      expect(history.length).toBeLessThanOrEqual(10);

      // Verify most recent baseline is the best one
      const latest = history[0];
      expect(latest.precision).toBeGreaterThan(0.95);
    });
  });

  describe('Database Integration', () => {
    it('should persist baseline metrics to baseline_metrics table', async () => {
      // Note: This test would require actual database schema for baseline_metrics table
      // For now, we verify file-based persistence works

      const detectorName = 'persistence-detector';
      const { predictions, groundTruth } = generateDetectionDataset(100, {
        precision: 0.91,
        recall: 0.94
      });

      const report = detectionMetrics.generateReport(predictions, groundTruth);
      const baselineId = testBaselineManager.recordBaseline(detectorName, {
        ...report,
        timestamp: new Date(),
        sampleSize: 100,
        detectorVersion: '1.0'
      });

      // Verify baseline persisted to file system (fallback storage)
      const baselineFile = path.join(baselinesDir, `${baselineId}.json`);
      expect(fs.existsSync(baselineFile)).toBe(true);

      // Verify can be reloaded
      const reloaded = testBaselineManager.getLatestBaseline(detectorName);
      expect(reloaded?.precision).toBeCloseTo(0.91, 1);
      expect(reloaded?.recall).toBeCloseTo(0.94, 1);
    });
  });
});

/**
 * Generate realistic detection dataset with target precision/recall
 */
function generateDetectionDataset(
  count: number,
  targets: { precision: number; recall: number }
): { predictions: DetectionResult[]; groundTruth: GroundTruthLabel[] } {
  const predictions: DetectionResult[] = [];
  const groundTruth: GroundTruthLabel[] = [];

  // Calculate required TP, FP, FN, TN to achieve targets
  const actualMalicious = Math.floor(count * 0.5); // 50% malicious
  const actualLegitimate = count - actualMalicious;

  // TP = recall * actualMalicious
  const truePositives = Math.floor(targets.recall * actualMalicious);

  // FP = TP / precision - TP
  const falsePositives = Math.floor(truePositives / targets.precision - truePositives);

  const falseNegatives = actualMalicious - truePositives;
  const trueNegatives = actualLegitimate - falsePositives;

  let automationIdx = 0;

  // Generate true positives
  for (let i = 0; i < truePositives; i++) {
    const id = `automation-${automationIdx++}`;
    predictions.push({
      automationId: id,
      predicted: 'malicious',
      confidence: 0.8 + Math.random() * 0.2,
      detectorName: 'test-detector',
      timestamp: new Date()
    });
    groundTruth.push({
      automationId: id,
      actual: 'malicious',
      confidence: 1.0,
      reviewers: ['test-reviewer'],
      rationale: 'Confirmed malicious automation'
    });
  }

  // Generate false positives
  for (let i = 0; i < falsePositives; i++) {
    const id = `automation-${automationIdx++}`;
    predictions.push({
      automationId: id,
      predicted: 'malicious',
      confidence: 0.5 + Math.random() * 0.3,
      detectorName: 'test-detector',
      timestamp: new Date()
    });
    groundTruth.push({
      automationId: id,
      actual: 'legitimate',
      confidence: 1.0,
      reviewers: ['test-reviewer'],
      rationale: 'Legitimate automation'
    });
  }

  // Generate false negatives
  for (let i = 0; i < falseNegatives; i++) {
    const id = `automation-${automationIdx++}`;
    predictions.push({
      automationId: id,
      predicted: 'legitimate',
      confidence: 0.3 + Math.random() * 0.2,
      detectorName: 'test-detector',
      timestamp: new Date()
    });
    groundTruth.push({
      automationId: id,
      actual: 'malicious',
      confidence: 1.0,
      reviewers: ['test-reviewer'],
      rationale: 'Missed malicious automation'
    });
  }

  // Generate true negatives
  for (let i = 0; i < trueNegatives; i++) {
    const id = `automation-${automationIdx++}`;
    predictions.push({
      automationId: id,
      predicted: 'legitimate',
      confidence: 0.2 + Math.random() * 0.3,
      detectorName: 'test-detector',
      timestamp: new Date()
    });
    groundTruth.push({
      automationId: id,
      actual: 'legitimate',
      confidence: 1.0,
      reviewers: ['test-reviewer'],
      rationale: 'Confirmed legitimate'
    });
  }

  return { predictions, groundTruth };
}
